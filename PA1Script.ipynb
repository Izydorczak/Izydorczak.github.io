{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.4"
    },
    "colab": {
      "name": "PA1Script.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Izydorczak/Izydorczak.github.io/blob/master/PA1Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rhqKktXOMIq",
        "colab_type": "text"
      },
      "source": [
        "# CSE474/574 - Programming Assignment 1\n",
        "\n",
        "For grading, we will execute the submitted notebook as follows:\n",
        "\n",
        "```shell\n",
        "jupyter nbconvert --to python PA1Script.ipynb\n",
        "python PA1Script.py\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9uYsSoWOMI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7GmNqM6OMI_",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 - Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEaKky-5OMJA",
        "colab_type": "text"
      },
      "source": [
        "### Problem 1 - Linear Regression with Direct Minimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Irsnj_OMJB",
        "colab_type": "code",
        "outputId": "ef97f536-7125-448c-8cd3-eee85fa2f498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('PROBLEM 1')\n",
        "print('----------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROBLEM 1\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfO0qA2HOMJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learnOLERegression(X,y):\n",
        "    # Inputs:                                                         \n",
        "    # X = N x d \n",
        "    # y = N x 1                                                               \n",
        "    # Output: \n",
        "    # w = d x 1 \n",
        "    w = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.transpose(),X)),X.transpose()),y)\n",
        "\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    #w = np.zeros((X.shape[0],1))\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7n3tHtUOMJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testOLERegression(w,Xtest,ytest):\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # Xtest = N x d\n",
        "    # ytest = N x 1\n",
        "    # Output:\n",
        "    # rmse = scalar value\n",
        "    #print(ytest.shape, Xtest.shape, w.shape)\n",
        "    vec = ytest - np.matmul(Xtest,w)\n",
        "    \n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    rmse = ((1/len(ytest))* np.matmul(vec.transpose(),vec))**.5\n",
        "    return rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qffiRhKOMJU",
        "colab_type": "code",
        "outputId": "bf89d9d9-6519-496d-e008-049cf9b1e142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        " \n",
        "Xtrain,ytrain,Xtest,ytest = pickle.load(open('diabetes.pickle','rb'),encoding='latin1') \n",
        "\n",
        "# Xtrain,ytrain,Xtest,ytest = pickle.load(io.BytesIO(uploaded[‘diabetes.pickle’]))  \n",
        "# add intercept\n",
        "x1 = np.ones((len(Xtrain),1))\n",
        "#print(Xtrain.shape)  242 by 64\n",
        "#print(x1.shape)  242 by 1\n",
        "x2 = np.ones((len(Xtest),1))\n",
        "#print(x2[:10])\n",
        "#print(ytrain[:10])\n",
        "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
        "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
        "\n",
        "w = learnOLERegression(Xtrain,ytrain)\n",
        "w_i = learnOLERegression(Xtrain_i,ytrain)\n",
        "print(w[:10])\n",
        "rmse = testOLERegression(w,Xtrain,ytrain)\n",
        "rmse_i = testOLERegression(w_i,Xtrain_i,ytrain)\n",
        "print('RMSE without intercept on train data - %.2f'%rmse)\n",
        "print('RMSE with intercept on train data - %.2f'%rmse_i)\n",
        "\n",
        "rmse = testOLERegression(w,Xtest,ytest)\n",
        "rmse_i = testOLERegression(w_i,Xtest_i,ytest)\n",
        "print('RMSE without intercept on test data - %.2f'%rmse)\n",
        "print('RMSE with intercept on test data - %.2f'%rmse_i)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-666601e9a98d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Xtrain,ytrain,Xtest,ytest = pickle.load(io.BytesIO(uploaded[‘diabetes.pickle’]))\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqPfHPcMOMJZ",
        "colab_type": "text"
      },
      "source": [
        "### Problem 2 - Linear Regression with Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOVJzEaeOMJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('PROBLEM 2')\n",
        "print('----------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWm-EpRFOMJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regressionObjVal(w, X, y):\n",
        "\n",
        "    # compute squared error (scalar) with respect\n",
        "    # to w (vector) for the given data X and y      \n",
        "    #\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # error = scalar value\n",
        "    vec = y - np.dot(X,w)\n",
        "    \n",
        "    \n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    error = (1/2)* np.dot(vec.transpose(),vec)\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    #error = 0\n",
        "    #print(error[0][0])\n",
        "    return error[0][0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSXWApZjOMJj",
        "colab_type": "code",
        "outputId": "1418aecb-b4dc-4890-9e44-ee827e18bf59",
        "colab": {}
      },
      "source": [
        "w = [[0],[0],[0]]\n",
        "X = [[1,2,3],\n",
        "    [4,5,6],\n",
        "    [7,8,9],\n",
        "    [10,11,12]]\n",
        "y = [[1],[1],[1],[1]]\n",
        "regressionObjVal(w,X,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tizu5STnOMJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regressionGradient(w, X, y):\n",
        "\n",
        "    # compute gradient of squared error (scalar) with respect\n",
        "    # to w (vector) for the given data X and y   \n",
        "    \n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # gradient = d length vector (not a d x 1 matrix)\n",
        "\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE \n",
        "    error_grad = np.matmul(np.matmul(X.transpose(),X),w)- np.matmul(X.transpose(),y) \n",
        "    #error_grad = np.zeros((X.shape[1],))\n",
        "    #print('error_grad ',error_grad)\n",
        "    #print(error_grad[0:len(w)][0])\n",
        "    return error_grad[0:len(w)][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgavY_4fOMJu",
        "colab_type": "code",
        "outputId": "b570ef4d-25df-42c2-8a75-7164b2afae60",
        "colab": {}
      },
      "source": [
        "Xtrain,ytrain,Xtest,ytest = pickle.load(open('diabetes.pickle','rb'),encoding='latin1')   \n",
        "# add intercept\n",
        "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
        "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
        "args = (Xtrain_i,ytrain)\n",
        "opts = {'maxiter' : 50}    # Preferred value.    \n",
        "w_init = np.zeros((Xtrain_i.shape[1],1))\n",
        "#print(ytrain.shape)\n",
        "soln = minimize(regressionObjVal, w_init, jac=regressionGradient, args=args,method='CG', options=opts)\n",
        "w = np.transpose(np.array(soln.x))\n",
        "w = w[:,np.newaxis]\n",
        "rmse = testOLERegression(w,Xtrain_i,ytrain)\n",
        "print('Gradient Descent Linear Regression RMSE on train data - %.2f'%rmse)\n",
        "rmse = testOLERegression(w,Xtest_i,ytest)\n",
        "print('Gradient Descent Linear Regression RMSE on test data - %.2f'%rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient Descent Linear Regression RMSE on train data - 128.34\n",
            "Gradient Descent Linear Regression RMSE on test data - 114.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrdBkUN_OMJ3",
        "colab_type": "text"
      },
      "source": [
        "## Part 2 - Linear Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fsSGsGJOMJ6",
        "colab_type": "text"
      },
      "source": [
        "### Problem 3 - Perceptron using Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnPpfmvCOMJ7",
        "colab_type": "code",
        "outputId": "9ac78b8b-5cc1-4e4f-e036-c69b2cbdfd78",
        "colab": {}
      },
      "source": [
        "print('PROBLEM 3')\n",
        "print('----------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROBLEM 3\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux4zNdPlOMJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictLinearModel(w,Xtest):\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # Xtest = N x d\n",
        "    # Output:\n",
        "    # ypred = N x 1 vector of predictions\n",
        "    y1 = np.dot(Xtest,w)\n",
        "    ypred = y1 / np.absolute(y1)\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    #ypred = np.zeros([Xtest.shape[0],1])\n",
        "    \n",
        "    return ypred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuXTorQSOMKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateLinearModel(w,Xtest,ytest):\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # Xtest = N x d\n",
        "    # ytest = N x 1\n",
        "    # Output:\n",
        "    # acc = scalar values\n",
        "    ypred = predictLinearModel(w,Xtest)\n",
        "    print((np.where(ypred*ytest==1)[0]))\n",
        "    acc = len(np.where(ypred*ytest == 1)[0])/len(ypred)\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    #acc = 0\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF1YEWVXOMKH",
        "colab_type": "code",
        "outputId": "b5be95b2-1e00-4bfe-bf2a-bd96270095a6",
        "colab": {}
      },
      "source": [
        "Xtrain,ytrain, Xtest, ytest = pickle.load(open('sample.pickle','rb')) \n",
        "# add intercept\n",
        "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
        "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
        "print(Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape)\n",
        "args = (Xtrain_i,ytrain)\n",
        "opts = {'maxiter' : 50}    # Preferred value.    \n",
        "w_init = np.zeros((Xtrain_i.shape[1],1))\n",
        "soln = minimize(regressionObjVal, w_init, jac=regressionGradient, args=args,method='CG', options=opts)\n",
        "w = np.transpose(np.array(soln.x))\n",
        "print('w ',w)\n",
        "w = w[:,np.newaxis]\n",
        "print('w ',w)\n",
        "acc = evaluateLinearModel(w,Xtrain_i,ytrain)\n",
        "print('Perceptron Accuracy on train data - %.2f'%acc)\n",
        "acc = evaluateLinearModel(w,Xtest_i,ytest)\n",
        "print('Perceptron Accuracy on test data - %.2f'%acc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 2) (100, 1) (100, 2) (100, 1)\n",
            "w  [ 0.01063972  0.01063972  0.01063972]\n",
            "w  [[ 0.01063972]\n",
            " [ 0.01063972]\n",
            " [ 0.01063972]]\n",
            "[ 0  1  2  4  7  9 11 15 16 17 18 20 23 24 25 27 28 30 31 37 38 39 40 41 43\n",
            " 48 50 51 52 53 57 63 66 69 70 71 72 73 77 79 80 82 85 86 87 88 89 90 91 95\n",
            " 96]\n",
            "Perceptron Accuracy on train data - 0.51\n",
            "[ 3  9 10 11 12 13 14 18 19 26 27 30 35 39 40 42 44 45 48 50 51 53 54 58 61\n",
            " 65 66 71 75 80 84 90 91 92 95 97 98]\n",
            "Perceptron Accuracy on test data - 0.37\n",
            "[[ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 2.]\n",
            " [ 2.]\n",
            " [ 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZnITRHYOMKL",
        "colab_type": "text"
      },
      "source": [
        "### Problem 4 - Logistic Regression Using Newton's Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37s1FzjHOMKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('PROBLEM 4')\n",
        "print('----------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFA2r28OMKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logisticObjVal(w, X, y):\n",
        "\n",
        "    # compute log-loss error (scalar) with respect\n",
        "    # to w (vector) for the given data X and y                               \n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # error = scalar\n",
        "    \n",
        "    \n",
        "    if len(w.shape) == 1:\n",
        "        w = w[:,np.newaxis]\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    error = 0\n",
        "    return error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqvbjpHyOMKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logisticGradient(w, X, y):\n",
        "\n",
        "    # compute the gradient of the log-loss error (vector) with respect\n",
        "    # to w (vector) for the given data X and y  \n",
        "    #\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # error = d length gradient vector (not a d x 1 matrix)\n",
        "\n",
        "    if len(w.shape) == 1:\n",
        "        w = w[:,np.newaxis]\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    gradient = np.zeros((w.shape[0],))\n",
        "    return gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Rk30eoOMKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logisticHessian(w, X, y):\n",
        "\n",
        "    # compute the Hessian of the log-loss error (matrix) with respect\n",
        "    # to w (vector) for the given data X and y                               \n",
        "    #\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # Hessian = d x d matrix\n",
        "    \n",
        "    if len(w.shape) == 1:\n",
        "        w = w[:,np.newaxis]\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    hessian = np.eye(X.shape[1])\n",
        "    return hessian"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "xdRbmXB0OMKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain,ytrain, Xtest, ytest = pickle.load(open('sample.pickle','rb')) \n",
        "# add intercept\n",
        "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
        "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
        "\n",
        "args = (Xtrain_i,ytrain)\n",
        "opts = {'maxiter' : 50}    # Preferred value.    \n",
        "w_init = np.zeros((Xtrain_i.shape[1],1))\n",
        "soln = minimize(logisticObjVal, w_init, jac=logisticGradient, hess=logisticHessian, args=args,method='Newton-CG', options=opts)\n",
        "w = np.transpose(np.array(soln.x))\n",
        "w = np.reshape(w,[len(w),1])\n",
        "acc = evaluateLinearModel(w,Xtrain_i,ytrain)\n",
        "print('Logistic Regression Accuracy on train data - %.2f'%acc)\n",
        "acc = evaluateLinearModel(w,Xtest_i,ytest)\n",
        "print('Logistic Regression Accuracy on test data - %.2f'%acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCqLTqDjOMKl",
        "colab_type": "text"
      },
      "source": [
        "### Problem 5 - Support Vector Machines Using Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVIy9PY1OMKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('PROBLEM 5')\n",
        "print('----------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuiqsws_OMKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainSGDSVM(X,y,T,eta=0.01):\n",
        "    # learn a linear SVM by implementing the SGD algorithm\n",
        "    #\n",
        "    # Inputs:\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # T = number of iterations\n",
        "    # eta = learning rate\n",
        "    # Output:\n",
        "    # weight vector, w = d x 1\n",
        "    \n",
        "    # IMPLEMENT THIS METHOD\n",
        "    w = np.zeros([X.shape[1],1])\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX1eygPDOMKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain,ytrain, Xtest, ytest = pickle.load(open('sample.pickle','rb')) \n",
        "# add intercept\n",
        "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
        "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
        "\n",
        "args = (Xtrain_i,ytrain)\n",
        "w = trainSGDSVM(Xtrain_i,ytrain,100,0.01)\n",
        "acc = evaluateLinearModel(w,Xtrain_i,ytrain)\n",
        "print('SVM Accuracy on train data - %.2f'%acc)\n",
        "acc = evaluateLinearModel(w,Xtest_i,ytest)\n",
        "print('SVM Accuracy on test data - %.2f'%acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZJBftAPOMKw",
        "colab_type": "text"
      },
      "source": [
        "### Problem 6 - Plotting decision boundaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhMSVm66OMKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Problem 6')\n",
        "print('---------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5rJtG8GOMLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotBoundaries(w,X,y):\n",
        "    # plotting boundaries\n",
        "\n",
        "    mn = np.min(X,axis=0)\n",
        "    mx = np.max(X,axis=0)\n",
        "    x1 = np.linspace(mn[1],mx[1],100)\n",
        "    x2 = np.linspace(mn[2],mx[2],100)\n",
        "    xx1,xx2 = np.meshgrid(x1,x2)\n",
        "    xx = np.zeros((x1.shape[0]*x2.shape[0],2))\n",
        "    xx[:,0] = xx1.ravel()\n",
        "    xx[:,1] = xx2.ravel()\n",
        "    xx_i = np.concatenate((np.ones((xx.shape[0],1)), xx), axis=1)\n",
        "    ypred = predictLinearModel(w,xx_i)\n",
        "    ax.contourf(x1,x2,ypred.reshape((x1.shape[0],x2.shape[0])),alpha=0.3,cmap='cool')\n",
        "    ax.scatter(X[:,1],X[:,2],c=y.flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-ByABL1OMLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain,ytrain, Xtest, ytest = pickle.load(open('sample.pickle','rb')) \n",
        "# add intercept\n",
        "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
        "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
        "\n",
        "# Replace next three lines with code for learning w using the three methods\n",
        "w_perceptron = np.zeros((Xtrain_i.shape[1],1))\n",
        "w_logistic = np.zeros((Xtrain_i.shape[1],1))\n",
        "w_svm = np.zeros((Xtrain_i.shape[1],1))\n",
        "fig = plt.figure(figsize=(20,6))\n",
        "\n",
        "ax = plt.subplot(1,3,1)\n",
        "plotBoundaries(w_perceptron,Xtrain_i,ytrain)\n",
        "ax.set_title('Perceptron')\n",
        "\n",
        "ax = plt.subplot(1,3,2)\n",
        "plotBoundaries(w_logistic,Xtrain_i,ytrain)\n",
        "ax.set_title('Logistic Regression')\n",
        "\n",
        "ax = plt.subplot(1,3,3)\n",
        "plotBoundaries(w_svm,Xtrain_i,ytrain)\n",
        "ax.set_title('SVM')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}